{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('punkt_tab')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import TfidfModel\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "import json\n",
    "\n",
    "\n",
    "# Data Modeling \n",
    "# pick two topics to compare\n",
    "# develop a way to identify which topic a post is talking about \n",
    "# check occurences of different topics of conversation over time\n",
    "#   could these different conversation topics appear during a game period more often?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def text2tokens(text):\n",
    "\tstop_words = set(stopwords.words('english'))\n",
    "\tps = PorterStemmer()\n",
    "\ttext = text.lower()\n",
    "\ttextList = word_tokenize(text)\n",
    "\ttextList = [word for word in textList if word not in stop_words and len(word) >= 3]\n",
    "\n",
    "\ttextList = [ps.stem(word) for word in textList]\n",
    "\treturn textList\n",
    "    \n",
    "\n",
    "def gen_bow(df, column):\n",
    "\tdf['tokens'] = df[column].apply(text2tokens)\n",
    "\tdct = Dictionary(df['tokens'])\n",
    "\tdct.filter_extremes(no_below=5, no_above=0.5)\n",
    "\tdf['bow'] = df['tokens'].apply(dct.doc2bow)\n",
    "\tworddict = {}\n",
    "\n",
    "\tfor i in range(len(df)):\n",
    "\t\tfor token in df.at[i,'bow']:\n",
    "\t\t\tif token in list(worddict.keys()):\n",
    "\t\t\t\tworddict[token] += 1\n",
    "\t\t\telse: \n",
    "\t\t\t\tworddict[token] = 1\n",
    "\n",
    "\tdf.drop('tokens', axis=1, inplace=True)\t\n",
    "\treturn df, worddict\n",
    "\n",
    "def get_post(jobj):\n",
    "\tdata_obj = jobj[0]['data']['children'][0]['data']\n",
    "\ttxt = data_obj['selftext']\n",
    "\tauthor = data_obj['author']\n",
    "\ttime = data_obj['created_utc']\n",
    "\t\n",
    "\treturn {\n",
    "\t\t'author': author,\n",
    "\t\t'created_utc': time,\n",
    "\t\t'text': txt\n",
    "\t}\n",
    "\n",
    "def get_comment(jobj):\n",
    "\tcomments = []\n",
    "\tfor comment in jobj[1]['data']['children']:\n",
    "\t\tif 'author' in comment['data']\\\n",
    "\t\tand 'created_utc' in comment['data']\\\n",
    "\t\tand 'body' in comment['data']:\n",
    "\t\t\tcobj = {\n",
    "\t\t\t\t'author': comment['data']['author'],\n",
    "\t\t\t\t'created_utc': comment['data']['created_utc'],\n",
    "\t\t\t\t'text': comment['data']['body']\n",
    "\t\t\t}\n",
    "\t\t\tcomments.append(cobj)\n",
    "\n",
    "\treturn comments\n",
    "\n",
    "# print(text2tokens(\"In this offering, one only has to view the current Westminster Kennel Club's annual offering to see the parallels.\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 2 column 1 (char 408858)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \tlines \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mreadlines()\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines:\n\u001b[0;32m----> 7\u001b[0m \tdata_obj \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(line)\n\u001b[1;32m      8\u001b[0m \tdobj \u001b[38;5;241m=\u001b[39m get_post(data_obj)\n\u001b[1;32m      9\u001b[0m \torioles_posts\u001b[38;5;241m.\u001b[39mappend(dobj)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/json/__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[0;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _default_decoder\u001b[38;5;241m.\u001b[39mdecode(s)\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/json/decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w\u001b[38;5;241m=\u001b[39mWHITESPACE\u001b[38;5;241m.\u001b[39mmatch):\n\u001b[1;32m    333\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;124;03m    containing a JSON document).\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \n\u001b[1;32m    336\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 337\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw_decode(s, idx\u001b[38;5;241m=\u001b[39m_w(s, \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mend())\n\u001b[1;32m    338\u001b[0m     end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/json/decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    353\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscan_once(s, idx)\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m--> 355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 2 column 1 (char 408858)"
     ]
    }
   ],
   "source": [
    "orioles_posts = []\n",
    "\n",
    "with open('orioles.json', 'r') as f:\n",
    "\tlines = f.readlines()\n",
    "\n",
    "for line in lines:\n",
    "\tdata_obj = json.loads(line)\n",
    "\tdobj = get_post(data_obj)\n",
    "\torioles_posts.append(dobj)\n",
    "\tcomments = get_comment(data_obj)\n",
    "\torioles_posts.extend(comments)\n",
    "\n",
    "orioles_df = pd.DataFrame(orioles_posts)\n",
    "\t# data = json.load(f)\n",
    "\t# orioles_df = pd.json_normalize(data, record_path='items')\n",
    "\t# orioles_df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
