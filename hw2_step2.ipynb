{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('punkt_tab')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import TfidfModel\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "import json\n",
    "\n",
    "\n",
    "# Data Modeling \n",
    "# pick two topics to compare\n",
    "# develop a way to identify which topic a post is talking about \n",
    "# check occurences of different topics of conversation over time\n",
    "# could these different conversation topics appear during a game period more often?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text2tokens, gen_bow, porterstemmer\n",
    "\n",
    "ps = PorterStemmer()\n",
    "\n",
    "def text2tokens(text):\n",
    "\tstop_words = set(stopwords.words('english'))\n",
    "\ttext = str(text)\n",
    "\ttext = text.lower()\n",
    "\ttextList = word_tokenize(text)\n",
    "\ttextList = [word for word in textList if word not in stop_words and len(word) >= 3]\n",
    "\n",
    "\ttextList = [ps.stem(word) for word in textList]\n",
    "\treturn textList\n",
    "    \n",
    "def gen_bow(df, column):\n",
    "\tdf['tokens'] = df[column].apply(text2tokens)\n",
    "\tdct = Dictionary(df['tokens'])\n",
    "\tdct.filter_extremes(no_below=5, no_above=0.5)\n",
    "\tdf['bow'] = df['tokens'].apply(dct.doc2bow)\n",
    "\tworddict = {}\n",
    "\n",
    "\tfor i in range(len(df)):\n",
    "\t\tfor token in df.at[i,'bow']:\n",
    "\t\t\tif token in list(worddict.keys()):\n",
    "\t\t\t\tworddict[token] += 1\n",
    "\t\t\telse: \n",
    "\t\t\t\tworddict[token] = 1\n",
    "\n",
    "\tdf.drop('tokens', axis=1, inplace=True)\t\n",
    "\treturn df, worddict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>time_of_post</th>\n",
       "      <th>game</th>\n",
       "      <th>team</th>\n",
       "      <th>tokens</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3183</th>\n",
       "      <td>SHIT PISS AND CUM SHIT PISS AND CUM SHIT PISS ...</td>\n",
       "      <td>2019-10-20</td>\n",
       "      <td>[]</td>\n",
       "      <td>BOS</td>\n",
       "      <td>[shit, piss, cum, shit, piss, cum, shit, piss,...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3166</th>\n",
       "      <td>Congrats, Houston!\\n\\nFUCK THE YANKEES\\n\\nFUCK...</td>\n",
       "      <td>2019-10-20</td>\n",
       "      <td>[]</td>\n",
       "      <td>BOS</td>\n",
       "      <td>[congrat, houston, fuck, yanke, fuck, yanke, f...</td>\n",
       "      <td>0.152416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1487</th>\n",
       "      <td>FUCK CHRIS SALE AND HIS GOOFY ASS DELIVERY\\n\\n...</td>\n",
       "      <td>2019-09-10</td>\n",
       "      <td>['401076896']</td>\n",
       "      <td>NYY</td>\n",
       "      <td>[fuck, chri, sale, goofi, ass, deliveri, fuck,...</td>\n",
       "      <td>0.226766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>912</th>\n",
       "      <td>Fuck you Kluber, Fuck you Bauer, Fuck you Jose...</td>\n",
       "      <td>2017-10-11</td>\n",
       "      <td>[]</td>\n",
       "      <td>NYY</td>\n",
       "      <td>[fuck, kluber, fuck, bauer, fuck, jose, ramire...</td>\n",
       "      <td>0.234201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2459</th>\n",
       "      <td>Fuck this fucking bullshit\\n\\nDavid price has ...</td>\n",
       "      <td>2018-09-19</td>\n",
       "      <td>['380919110']</td>\n",
       "      <td>NYY</td>\n",
       "      <td>[fuck, fuck, bullshit, david, price, domin, ya...</td>\n",
       "      <td>0.234201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2742</th>\n",
       "      <td>David Ortiz changed my life and I'll always ca...</td>\n",
       "      <td>2016-10-12</td>\n",
       "      <td>[]</td>\n",
       "      <td>BOS</td>\n",
       "      <td>[david, ortiz, chang, life, 'll, alway, carri,...</td>\n",
       "      <td>0.639405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5946</th>\n",
       "      <td>Is...this post in the right place?  Have I mis...</td>\n",
       "      <td>2016-04-26</td>\n",
       "      <td>['360426114']</td>\n",
       "      <td>TOR</td>\n",
       "      <td>[..., post, right, place, miss, someth, know, ...</td>\n",
       "      <td>0.639405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2478</th>\n",
       "      <td>Gary Sanchez has had one of the most up and do...</td>\n",
       "      <td>2021-06-24</td>\n",
       "      <td>['401228171']</td>\n",
       "      <td>NYY</td>\n",
       "      <td>[gari, sanchez, one, career, athlet, last, thi...</td>\n",
       "      <td>0.776952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3291</th>\n",
       "      <td>Excuse the throwaway (for anonymity), but I pr...</td>\n",
       "      <td>2018-10-19</td>\n",
       "      <td>['381018118']</td>\n",
       "      <td>BOS</td>\n",
       "      <td>[excus, throwaway, anonym, promis, say, true, ...</td>\n",
       "      <td>0.914498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4405</th>\n",
       "      <td>I know many of you will probably yeet me out t...</td>\n",
       "      <td>2020-12-28</td>\n",
       "      <td>[]</td>\n",
       "      <td>TB</td>\n",
       "      <td>[know, mani, probabl, yeet, window, read, enti...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6630 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text time_of_post  \\\n",
       "3183  SHIT PISS AND CUM SHIT PISS AND CUM SHIT PISS ...   2019-10-20   \n",
       "3166  Congrats, Houston!\\n\\nFUCK THE YANKEES\\n\\nFUCK...   2019-10-20   \n",
       "1487  FUCK CHRIS SALE AND HIS GOOFY ASS DELIVERY\\n\\n...   2019-09-10   \n",
       "912   Fuck you Kluber, Fuck you Bauer, Fuck you Jose...   2017-10-11   \n",
       "2459  Fuck this fucking bullshit\\n\\nDavid price has ...   2018-09-19   \n",
       "...                                                 ...          ...   \n",
       "2742  David Ortiz changed my life and I'll always ca...   2016-10-12   \n",
       "5946  Is...this post in the right place?  Have I mis...   2016-04-26   \n",
       "2478  Gary Sanchez has had one of the most up and do...   2021-06-24   \n",
       "3291  Excuse the throwaway (for anonymity), but I pr...   2018-10-19   \n",
       "4405  I know many of you will probably yeet me out t...   2020-12-28   \n",
       "\n",
       "               game team                                             tokens  \\\n",
       "3183             []  BOS  [shit, piss, cum, shit, piss, cum, shit, piss,...   \n",
       "3166             []  BOS  [congrat, houston, fuck, yanke, fuck, yanke, f...   \n",
       "1487  ['401076896']  NYY  [fuck, chri, sale, goofi, ass, deliveri, fuck,...   \n",
       "912              []  NYY  [fuck, kluber, fuck, bauer, fuck, jose, ramire...   \n",
       "2459  ['380919110']  NYY  [fuck, fuck, bullshit, david, price, domin, ya...   \n",
       "...             ...  ...                                                ...   \n",
       "2742             []  BOS  [david, ortiz, chang, life, 'll, alway, carri,...   \n",
       "5946  ['360426114']  TOR  [..., post, right, place, miss, someth, know, ...   \n",
       "2478  ['401228171']  NYY  [gari, sanchez, one, career, athlet, last, thi...   \n",
       "3291  ['381018118']  BOS  [excus, throwaway, anonym, promis, say, true, ...   \n",
       "4405             []   TB  [know, mani, probabl, yeet, window, read, enti...   \n",
       "\n",
       "      sentiment  \n",
       "3183   0.000000  \n",
       "3166   0.152416  \n",
       "1487   0.226766  \n",
       "912    0.234201  \n",
       "2459   0.234201  \n",
       "...         ...  \n",
       "2742   0.639405  \n",
       "5946   0.639405  \n",
       "2478   0.776952  \n",
       "3291   0.914498  \n",
       "4405   1.000000  \n",
       "\n",
       "[6630 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gdf = pd.read_csv('hw2_step1_games.csv')\n",
    "rdf = pd.read_csv('hw2_step1_reddit_posts.csv')\n",
    "posNegWords = pd.read_excel('posNegList.xlsx').dropna()\n",
    "# print(posNegWords.dtypes)\n",
    "\n",
    "\n",
    "posWords = [ps.stem(word) for word in posNegWords['Positive Sense Word List'].to_list()]\n",
    "negWords = [ps.stem(word) for word in posNegWords['Negative Sense Word List'].to_list()]\n",
    "\n",
    "\n",
    "\n",
    "def get_sentiment(list):\n",
    "\tsentiment = 0\n",
    "\t\n",
    "\tfor word in list:\n",
    "\t\tif word in posWords:\n",
    "\t\t\tsentiment += 1\n",
    "\t\telif word in negWords:\n",
    "\t\t\tsentiment -= 1\n",
    "\t\n",
    "\treturn sentiment\n",
    "\t\t\t\n",
    "\n",
    "\n",
    "# rdf, word_dict = gen_bow(rdf, 'text')\n",
    "rdf['tokens'] = rdf['text'].apply(text2tokens)\n",
    "# rdf['sentiment'] = rdf['tokens'].apply(get_sentiment)\n",
    "\n",
    "sent_array = np.array(rdf['tokens'].apply(get_sentiment))\n",
    "max_sent = sent_array.max()\n",
    "min_sent = sent_array.min()\n",
    "\n",
    "rdf['sentiment'] = (sent_array - min_sent) / (max_sent - min_sent)\n",
    "\n",
    "display(rdf.sort_values(by='sentiment'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>time_of_post</th>\n",
       "      <th>game</th>\n",
       "      <th>team</th>\n",
       "      <th>tokens</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>team_performance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1170</th>\n",
       "      <td>THESE VAGABOND SHOESSSSSSS</td>\n",
       "      <td>2017-10-17</td>\n",
       "      <td>['371016110', '371017110']</td>\n",
       "      <td>NYY</td>\n",
       "      <td>[vagabond, shoesssssss]</td>\n",
       "      <td>0.256506</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>844</th>\n",
       "      <td>Can we get candle flairs up in here</td>\n",
       "      <td>2020-09-05</td>\n",
       "      <td>['401234674', '401226263']</td>\n",
       "      <td>NYY</td>\n",
       "      <td>[get, candl, flair]</td>\n",
       "      <td>0.252788</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>843</th>\n",
       "      <td>I drunk bought a pair of boosts tonight after ...</td>\n",
       "      <td>2020-09-05</td>\n",
       "      <td>['401234674', '401226263']</td>\n",
       "      <td>NYY</td>\n",
       "      <td>[drunk, bought, pair, boost, tonight, game, mo...</td>\n",
       "      <td>0.267658</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>842</th>\n",
       "      <td>Sorry, but I can't code in the scent of candle...</td>\n",
       "      <td>2020-09-05</td>\n",
       "      <td>['401234674', '401226263']</td>\n",
       "      <td>NYY</td>\n",
       "      <td>[sorri, n't, code, scent, candl, css]</td>\n",
       "      <td>0.260223</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>841</th>\n",
       "      <td>ðŸ•¯ðŸŒ¸Pinstripe PeoniesðŸŒ¸ðŸ•¯</td>\n",
       "      <td>2020-09-05</td>\n",
       "      <td>['401234674', '401226263']</td>\n",
       "      <td>NYY</td>\n",
       "      <td>[ðŸ•¯ðŸŒ¸pinstrip, peoniesðŸŒ¸ðŸ•¯]</td>\n",
       "      <td>0.256506</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499</th>\n",
       "      <td>#DAAAAAAAA JANKEES WIN!</td>\n",
       "      <td>2019-09-09</td>\n",
       "      <td>['401076871', '401076886']</td>\n",
       "      <td>NYY</td>\n",
       "      <td>[daaaaaaaa, janke, win]</td>\n",
       "      <td>0.260223</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1498</th>\n",
       "      <td>FAWK THOSE GUYS!!! #FEELSGOODMAN!!!</td>\n",
       "      <td>2019-09-09</td>\n",
       "      <td>['401076871', '401076886']</td>\n",
       "      <td>NYY</td>\n",
       "      <td>[fawk, guy, feelsgoodman]</td>\n",
       "      <td>0.256506</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1497</th>\n",
       "      <td>You love to see it</td>\n",
       "      <td>2019-09-09</td>\n",
       "      <td>['401076871', '401076886']</td>\n",
       "      <td>NYY</td>\n",
       "      <td>[love, see]</td>\n",
       "      <td>0.260223</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1494</th>\n",
       "      <td>Fuck Boston!</td>\n",
       "      <td>2019-09-09</td>\n",
       "      <td>['401076871', '401076886']</td>\n",
       "      <td>NYY</td>\n",
       "      <td>[fuck, boston]</td>\n",
       "      <td>0.252788</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1502</th>\n",
       "      <td>WHAT IT DO BAYBEEE</td>\n",
       "      <td>2019-09-09</td>\n",
       "      <td>['401076871', '401076886']</td>\n",
       "      <td>NYY</td>\n",
       "      <td>[baybee]</td>\n",
       "      <td>0.256506</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6630 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text time_of_post  \\\n",
       "1170                         THESE VAGABOND SHOESSSSSSS   2017-10-17   \n",
       "844                 Can we get candle flairs up in here   2020-09-05   \n",
       "843   I drunk bought a pair of boosts tonight after ...   2020-09-05   \n",
       "842   Sorry, but I can't code in the scent of candle...   2020-09-05   \n",
       "841                               ðŸ•¯ðŸŒ¸Pinstripe PeoniesðŸŒ¸ðŸ•¯   2020-09-05   \n",
       "...                                                 ...          ...   \n",
       "1499                            #DAAAAAAAA JANKEES WIN!   2019-09-09   \n",
       "1498                FAWK THOSE GUYS!!! #FEELSGOODMAN!!!   2019-09-09   \n",
       "1497                                 You love to see it   2019-09-09   \n",
       "1494                                       Fuck Boston!   2019-09-09   \n",
       "1502                                 WHAT IT DO BAYBEEE   2019-09-09   \n",
       "\n",
       "                            game team  \\\n",
       "1170  ['371016110', '371017110']  NYY   \n",
       "844   ['401234674', '401226263']  NYY   \n",
       "843   ['401234674', '401226263']  NYY   \n",
       "842   ['401234674', '401226263']  NYY   \n",
       "841   ['401234674', '401226263']  NYY   \n",
       "...                          ...  ...   \n",
       "1499  ['401076871', '401076886']  NYY   \n",
       "1498  ['401076871', '401076886']  NYY   \n",
       "1497  ['401076871', '401076886']  NYY   \n",
       "1494  ['401076871', '401076886']  NYY   \n",
       "1502  ['401076871', '401076886']  NYY   \n",
       "\n",
       "                                                 tokens  sentiment  \\\n",
       "1170                            [vagabond, shoesssssss]   0.256506   \n",
       "844                                 [get, candl, flair]   0.252788   \n",
       "843   [drunk, bought, pair, boost, tonight, game, mo...   0.267658   \n",
       "842               [sorri, n't, code, scent, candl, css]   0.260223   \n",
       "841                             [ðŸ•¯ðŸŒ¸pinstrip, peoniesðŸŒ¸ðŸ•¯]   0.256506   \n",
       "...                                                 ...        ...   \n",
       "1499                            [daaaaaaaa, janke, win]   0.260223   \n",
       "1498                          [fawk, guy, feelsgoodman]   0.256506   \n",
       "1497                                        [love, see]   0.260223   \n",
       "1494                                     [fuck, boston]   0.252788   \n",
       "1502                                           [baybee]   0.256506   \n",
       "\n",
       "      team_performance  \n",
       "1170              -2.0  \n",
       "844               -2.0  \n",
       "843               -2.0  \n",
       "842               -2.0  \n",
       "841               -2.0  \n",
       "...                ...  \n",
       "1499              -2.0  \n",
       "1498              -2.0  \n",
       "1497              -2.0  \n",
       "1494              -2.0  \n",
       "1502              -2.0  \n",
       "\n",
       "[6630 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gdf = gdf.drop_duplicates()\n",
    "\n",
    "for idx, row in gdf.iterrows():\n",
    "    diff = row['home-score'] - row['away-score']\n",
    "    if diff > 0:\n",
    "        gdf.at[idx, 'winner'] = row['home']\n",
    "    elif diff < 0:\n",
    "        gdf.at[idx, 'winner'] = row['away']\n",
    "    else:\n",
    "        gdf.at[idx, 'winner'] = 'N/A'\n",
    "\n",
    "bal_games = gdf.loc[(gdf['home'] == 'BAL') | (gdf['away'] == 'BAL')]\n",
    "nyy_games = gdf.loc[(gdf['home'] == 'NYY') | (gdf['away'] == 'NYY')]\n",
    "bos_games = gdf.loc[(gdf['home'] == 'BOS') | (gdf['away'] == 'BOS')]\n",
    "tor_games = gdf.loc[(gdf['home'] == 'TOR') | (gdf['away'] == 'TOR')]\n",
    "tb_games = gdf.loc[(gdf['home'] == 'TB') | (gdf['away'] == 'TB')]\n",
    "\n",
    "team_sdfs = {\n",
    "    \"BAL\": bal_games,\n",
    "    \"NYY\": nyy_games,\n",
    "    \"BOS\": bos_games,\n",
    "    \"TOR\": tor_games,\n",
    "    \"TB\": tb_games\n",
    "}\n",
    "\n",
    "\n",
    "def game_outcome(game_ids, team):\n",
    "    win_diff = 0\n",
    "    team_games = team_sdfs[team]\n",
    "    games = []\n",
    "    for idx, row in team_games.iterrows():\n",
    "        game = str(row['game'])\n",
    "        if game in game_ids:\n",
    "            # display(row)\n",
    "            games.append(row)\n",
    "\n",
    "    for game in games:\n",
    "        if row['winner'] == team:\n",
    "            win_diff +=1\n",
    "        elif row['winner'] != 'N/A':\n",
    "            win_diff -= 1\n",
    "    return win_diff\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for idx, row in rdf.iterrows():\n",
    "    team = row['team']\n",
    "    # print(team)\n",
    "    game_ids = row['game']\n",
    "    # print(game_ids)\n",
    "\n",
    "    if len(game_ids) == 0:\n",
    "        rdf.at[idx, 'team_performance'] = 0\n",
    "    else:\n",
    "        outcome = game_outcome(game_ids, team)\n",
    "        rdf.at[idx, 'team_performance'] = outcome\n",
    "\n",
    "\n",
    "\n",
    "display(rdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf = rdf.sort_values(by='team_performance')\n",
    "gdf.to_csv('hw2_step2_games.csv')\n",
    "rdf.to_csv('hw2_step2_reddit_posts.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
